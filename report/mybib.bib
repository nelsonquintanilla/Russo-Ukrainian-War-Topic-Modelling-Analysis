@article{blei_probabilistic_2012,
	title = {Probabilistic topic models},
	volume = {55},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/2133806.2133826},
	doi = {10.1145/2133806.2133826},
	abstract = {Surveying a suite of algorithms that offer a solution to managing large document archives.},
	language = {en},
	number = {4},
	urldate = {2022-09-16},
	journal = {Communications of the ACM},
	author = {Blei, David M.},
	month = apr,
	year = {2012},
	pages = {77--84},
	file = {Blei - 2012 - Probabilistic topic models.pdf:/Users/nelsonquintanilla/Zotero/storage/I2J2PVHI/Blei - 2012 - Probabilistic topic models.pdf:application/pdf},
}

@article{blei_probabilistic_2010,
	title = {Probabilistic {Topic} {Models}},
	volume = {27},
	issn = {1558-0792},
	doi = {10.1109/MSP.2010.938079},
	abstract = {In this article, we review probabilistic topic models: graphical models that can be used to summarize a large collection of documents with a smaller number of distributions over words. Those distributions are called "topics" because, when fit to data, they capture the salient themes that run through the collection. We describe both finite-dimensional parametric topic models and their Bayesian nonparametric counterparts, which are based on the hierarchical Dirichlet process (HDP). We discuss two extensions of topic models to time-series data-one that lets the topics slowly change over time and one that lets the assumed prevalence of the topics change. Finally, we illustrate the application of topic models to nontext data, summarizing some recent research results in image analysis.},
	number = {6},
	journal = {IEEE Signal Processing Magazine},
	author = {Blei, David and Carin, Lawrence and Dunson, David},
	month = nov,
	year = {2010},
	note = {Conference Name: IEEE Signal Processing Magazine},
	keywords = {Analytical models, Bayesian methods, Computational modeling, Data models, Graphical models, Markov processes},
	pages = {55--65},
	file = {Blei - Probabilistic topic models.pdf:/Users/nelsonquintanilla/Zotero/storage/MAPDH4FW/Blei - Probabilistic topic models.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/nelsonquintanilla/Zotero/storage/XL5BIT9W/5563111.html:text/html;IEEE Xplore Full Text PDF:/Users/nelsonquintanilla/Zotero/storage/4CXA3DRX/Blei et al. - 2010 - Probabilistic Topic Models.pdf:application/pdf},
}

@article{blei_latent_nodate,
	title = {Latent {Dirichlet} {Allocation}},
	abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a ﬁnite mixture over an underlying set of topics. Each topic is, in turn, modeled as an inﬁnite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efﬁcient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classiﬁcation, and collaborative ﬁltering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
	language = {en},
	author = {Blei, David M},
	pages = {30},
	file = {Blei - Latent Dirichlet Allocation.pdf:/Users/nelsonquintanilla/Zotero/storage/VXMXVDHN/Blei - Latent Dirichlet Allocation.pdf:application/pdf},
}

@inproceedings{sievert_ldavis_2014,
	address = {Baltimore, Maryland, USA},
	title = {{LDAvis}: {A} method for visualizing and interpreting topics},
	shorttitle = {{LDAvis}},
	url = {http://aclweb.org/anthology/W14-3110},
	doi = {10.3115/v1/W14-3110},
	abstract = {We present LDAvis, a web-based interactive visualization of topics estimated using Latent Dirichlet Allocation that is built using a combination of R and D3. Our visualization provides a global view of the topics (and how they differ from each other), while at the same time allowing for a deep inspection of the terms most highly associated with each individual topic. First, we propose a novel method for choosing which terms to present to a user to aid in the task of topic interpretation, in which we deﬁne the relevance of a term to a topic. Second, we present results from a user study that suggest that ranking terms purely by their probability under a topic is suboptimal for topic interpretation. Last, we describe LDAvis, our visualization system that allows users to ﬂexibly explore topic-term relationships using relevance to better understand a ﬁtted LDA model.},
	language = {en},
	urldate = {2022-08-31},
	booktitle = {Proceedings of the {Workshop} on {Interactive} {Language} {Learning}, {Visualization}, and {Interfaces}},
	publisher = {Association for Computational Linguistics},
	author = {Sievert, Carson and Shirley, Kenneth},
	year = {2014},
	pages = {63--70},
	file = {Sievert and Shirley - 2014 - LDAvis A method for visualizing and interpreting .pdf:/Users/nelsonquintanilla/Zotero/storage/E4S6JPWG/Sievert and Shirley - 2014 - LDAvis A method for visualizing and interpreting .pdf:application/pdf},
}


