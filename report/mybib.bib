@article{blei_probabilistic_2012,
	title = {Probabilistic topic models},
	volume = {55},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/2133806.2133826},
	doi = {10.1145/2133806.2133826},
	abstract = {Surveying a suite of algorithms that offer a solution to managing large document archives.},
	language = {en},
	number = {4},
	urldate = {2022-09-16},
	journal = {Communications of the ACM},
	author = {Blei, David M.},
	month = apr,
	year = {2012},
	pages = {77--84},
	file = {Blei - 2012 - Probabilistic topic models.pdf:/Users/nelsonquintanilla/Zotero/storage/I2J2PVHI/Blei - 2012 - Probabilistic topic models.pdf:application/pdf},
}

@article{blei_probabilistic_2010,
	title = {Probabilistic {Topic} {Models}},
	volume = {27},
	issn = {1558-0792},
	doi = {10.1109/MSP.2010.938079},
	abstract = {In this article, we review probabilistic topic models: graphical models that can be used to summarize a large collection of documents with a smaller number of distributions over words. Those distributions are called "topics" because, when fit to data, they capture the salient themes that run through the collection. We describe both finite-dimensional parametric topic models and their Bayesian nonparametric counterparts, which are based on the hierarchical Dirichlet process (HDP). We discuss two extensions of topic models to time-series data-one that lets the topics slowly change over time and one that lets the assumed prevalence of the topics change. Finally, we illustrate the application of topic models to nontext data, summarizing some recent research results in image analysis.},
	number = {6},
	journal = {IEEE Signal Processing Magazine},
	author = {Blei, David and Carin, Lawrence and Dunson, David},
	month = nov,
	year = {2010},
	note = {Conference Name: IEEE Signal Processing Magazine},
	keywords = {Analytical models, Bayesian methods, Computational modeling, Data models, Graphical models, Markov processes},
	pages = {55--65},
	file = {Blei - Probabilistic topic models.pdf:/Users/nelsonquintanilla/Zotero/storage/MAPDH4FW/Blei - Probabilistic topic models.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/nelsonquintanilla/Zotero/storage/XL5BIT9W/5563111.html:text/html;IEEE Xplore Full Text PDF:/Users/nelsonquintanilla/Zotero/storage/4CXA3DRX/Blei et al. - 2010 - Probabilistic Topic Models.pdf:application/pdf},
}

@article{blei_latent_nodate,
	title = {Latent {Dirichlet} {Allocation}},
	abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a ﬁnite mixture over an underlying set of topics. Each topic is, in turn, modeled as an inﬁnite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efﬁcient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classiﬁcation, and collaborative ﬁltering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
	language = {en},
	author = {Blei, David M},
	pages = {30},
	file = {Blei - Latent Dirichlet Allocation.pdf:/Users/nelsonquintanilla/Zotero/storage/VXMXVDHN/Blei - Latent Dirichlet Allocation.pdf:application/pdf},
}

@inproceedings{sievert_ldavis_2014,
	address = {Baltimore, Maryland, USA},
	title = {{LDAvis}: {A} method for visualizing and interpreting topics},
	shorttitle = {{LDAvis}},
	url = {http://aclweb.org/anthology/W14-3110},
	doi = {10.3115/v1/W14-3110},
	abstract = {We present LDAvis, a web-based interactive visualization of topics estimated using Latent Dirichlet Allocation that is built using a combination of R and D3. Our visualization provides a global view of the topics (and how they differ from each other), while at the same time allowing for a deep inspection of the terms most highly associated with each individual topic. First, we propose a novel method for choosing which terms to present to a user to aid in the task of topic interpretation, in which we deﬁne the relevance of a term to a topic. Second, we present results from a user study that suggest that ranking terms purely by their probability under a topic is suboptimal for topic interpretation. Last, we describe LDAvis, our visualization system that allows users to ﬂexibly explore topic-term relationships using relevance to better understand a ﬁtted LDA model.},
	language = {en},
	urldate = {2022-08-31},
	booktitle = {Proceedings of the {Workshop} on {Interactive} {Language} {Learning}, {Visualization}, and {Interfaces}},
	publisher = {Association for Computational Linguistics},
	author = {Sievert, Carson and Shirley, Kenneth},
	year = {2014},
	pages = {63--70},
	file = {Sievert and Shirley - 2014 - LDAvis A method for visualizing and interpreting .pdf:/Users/nelsonquintanilla/Zotero/storage/E4S6JPWG/Sievert and Shirley - 2014 - LDAvis A method for visualizing and interpreting .pdf:application/pdf},
}

@article{jacobi_quantitative_2016,
	title = {Quantitative analysis of large amounts of journalistic texts using topic modelling},
	volume = {4},
	issn = {2167-0811, 2167-082X},
	url = {http://www.tandfonline.com/doi/full/10.1080/21670811.2015.1093271},
	doi = {10.1080/21670811.2015.1093271},
	language = {en},
	number = {1},
	urldate = {2022-09-17},
	journal = {Digital Journalism},
	author = {Jacobi, Carina and van Atteveldt, Wouter and Welbers, Kasper},
	month = jan,
	year = {2016},
	keywords = {automatic content analysis, Corrigendum, journalism, nuclear energy, topic models},
	pages = {89--106},
	file = {Jacobi et al. - 2016 - Quantitative analysis of large amounts of journali.pdf:/Users/nelsonquintanilla/Zotero/storage/GM26PM6G/Jacobi et al. - 2016 - Quantitative analysis of large amounts of journali.pdf:application/pdf;Snapshot:/Users/nelsonquintanilla/Zotero/storage/F4NA2GZ4/21670811.2015.html:text/html},
}

@article{caldara_effect_2022,
	title = {The {Effect} of the {War} in {Ukraine} on {Global} {Activity} and {Inflation}},
	url = {https://www.federalreserve.gov/econres/notes/feds-notes/the-effect-of-the-war-in-ukraine-on-global-activity-and-inflation-20220527.html},
	abstract = {The Federal Reserve Board of Governors in Washington DC.},
	language = {en},
	urldate = {2022-09-17},
	author = {Caldara, Dario and Conlisk, Sarah and Iacoviello, Matteo and Penn, Maddie},
	month = may,
	year = {2022},
	file = {Snapshot:/Users/nelsonquintanilla/Zotero/storage/C76JDUYI/the-effect-of-the-war-in-ukraine-on-global-activity-and-inflation-20220527.html:text/html},
}

@article{jelodar_latent_2019,
	title = {Latent {Dirichlet} allocation ({LDA}) and topic modeling: models, applications, a survey},
	volume = {78},
	issn = {1380-7501, 1573-7721},
	shorttitle = {Latent {Dirichlet} allocation ({LDA}) and topic modeling},
	url = {http://link.springer.com/10.1007/s11042-018-6894-4},
	doi = {10.1007/s11042-018-6894-4},
	abstract = {Topic modeling is one of the most powerful techniques in text mining for data mining, latent data discovery, and finding relationships among data and text documents. Researchers have published many articles in the field of topic modeling and applied in various fields such as software engineering, political science, medical and linguistic science, etc. There are various methods for topic modelling; Latent Dirichlet Allocation (LDA) is one of the most popular in this field. Researchers have proposed various models based on the LDA in topic modeling. According to previous work, this paper will be very useful and valuable for introducing LDA approaches in topic modeling. In this paper, we investigated highly scholarly articles (between 2003 to 2016) related to topic modeling based on LDA to discover the research development, current trends and intellectual structure of topic modeling. In addition, we summarize challenges and introduce famous tools and datasets in topic modeling based on LDA.},
	language = {en},
	number = {11},
	urldate = {2022-09-17},
	journal = {Multimedia Tools and Applications},
	author = {Jelodar, Hamed and Wang, Yongli and Yuan, Chi and Feng, Xia and Jiang, Xiahui and Li, Yanchao and Zhao, Liang},
	month = jun,
	year = {2019},
	pages = {15169--15211},
	file = {Jelodar et al. - 2019 - Latent Dirichlet allocation (LDA) and topic modeli.pdf:/Users/nelsonquintanilla/Zotero/storage/NW5KNSTF/Jelodar et al. - 2019 - Latent Dirichlet allocation (LDA) and topic modeli.pdf:application/pdf},
}

